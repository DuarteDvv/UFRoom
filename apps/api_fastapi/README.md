# API FastAPI - UFRoom AI Agent ü§ñ

Agente conversacional inteligente constru√≠do com FastAPI, LangGraph e Google Gemini AI. Ajuda estudantes a encontrar acomoda√ß√µes atrav√©s de conversa√ß√£o natural.

## üìã Sum√°rio

- [Tecnologias](#-tecnologias)
- [Instala√ß√£o](#-instala√ß√£o)
- [Configura√ß√£o](#-configura√ß√£o)
- [Executar](#-executar)
- [Estrutura](#-estrutura)
- [Como Funciona](#-como-funciona)
- [Endpoints](#-endpoints)
- [Troubleshooting](#-troubleshooting)

## üõ† Tecnologias

- **FastAPI** - Framework web ass√≠ncrono de alta performance
- **LangGraph** - Framework para orquestra√ß√£o de agentes com estados
- **LangChain** - Toolkit para integra√ß√£o com LLMs
- **Google Gemini AI** - Modelo de linguagem (gemini-1.5-flash)
- **Pydantic** - Valida√ß√£o de dados e schemas
- **Python 3.12+** - Linguagem de programa√ß√£o
- **UV** - Gerenciador de pacotes e ambientes virtuais ultrarr√°pido

## üì¶ Instala√ß√£o

### Pr√©-requisitos

- Python 3.12 ou superior
- Google Cloud account com Gemini API habilitada
- UV package manager (recomendado) ou pip

### 1. Instalar UV (Gerenciador Python)

UV √© um gerenciador de pacotes Python extremamente r√°pido, substituto do pip/poetry/conda.

```bash
# Linux/macOS
curl -LsSf https://astral.sh/uv/install.sh | sh

# Recarregar shell
source ~/.bashrc  # ou ~/.zshrc
```

### 2. Navegar para o Diret√≥rio

```bash
cd apps/api_fastapi
```

### 3. Criar Ambiente Virtual

```bash
# Criar ambiente virtual com Python 3.12
uv venv --python 3.12

# Ativar ambiente virtual
source .venv/bin/activate  # Linux/macOS
# ou
.venv\Scripts\activate     # Windows
```

### 4. Instalar Depend√™ncias

```bash
# Instalar a partir do requirements.txt
uv pip install -r requirements.txt
```

**Depend√™ncias instaladas:**
```txt
fastapi==0.115.6          # Framework web
uvicorn[standard]==0.34.0 # ASGI server
pydantic==2.10.4          # Valida√ß√£o de dados
python-dotenv==1.0.1      # Vari√°veis de ambiente
langgraph==0.2.59         # Orquestra√ß√£o de agentes
langchain-google-genai==2.0.8  # Integra√ß√£o Gemini
```

## ‚öôÔ∏è Configura√ß√£o

### 1. Criar Arquivo `.env`

```bash
cp example.env .env
```

### 2. Obter Google Gemini API Key

1. Acesse [Google AI Studio](https://aistudio.google.com/apikey)
2. Fa√ßa login com conta Google
3. Clique em "**Get API key**" ou "**Create API key**"
4. Selecione um projeto Google Cloud ou crie novo
5. Copie a chave gerada

**‚ö†Ô∏è Importante:** Gemini AI tem limites gratuitos:
- **Free tier:** 15 requisi√ß√µes/minuto, 1.5M tokens/dia
- **API Key gratuita:** N√£o requer billing inicial

### 3. Configurar `.env`

Edite o arquivo `.env`:

```env
GOOGLE_API_KEY=AIzaSy...sua_chave_gemini_aqui
```

## üöÄ Executar

### Modo Desenvolvimento

```bash
# Com UV (recomendado)
uv run uvicorn main:app --reload --host 0.0.0.0 --port 8000

# Ou com Python diretamente
python -m uvicorn main:app --reload
```

**Servidor dispon√≠vel em:** `http://localhost:8000`

### Modo Produ√ß√£o

```bash
uv run uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4
```

### Verificar Instala√ß√£o

```bash
# Health check
curl http://localhost:8000/

# Documenta√ß√£o interativa
# Navegador: http://localhost:8000/docs
```

## üìÅ Estrutura

```
apps/api_fastapi/
‚îú‚îÄ‚îÄ simple_agent/              # Implementa√ß√£o do agente
‚îÇ   ‚îú‚îÄ‚îÄ agent.py              # Defini√ß√£o do grafo LangGraph
‚îÇ   ‚îÇ                         # - N√≥s: search_node, respond_node
‚îÇ   ‚îÇ                         # - Fluxo condicional de estados
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ utils/                # Utilit√°rios do agente
‚îÇ       ‚îú‚îÄ‚îÄ context.py        # Context loader (dados externos)
‚îÇ       ‚îú‚îÄ‚îÄ prompt.py         # Prompts do sistema e usu√°rio
‚îÇ       ‚îú‚îÄ‚îÄ request_schema.py # Schema Pydantic para requests
‚îÇ       ‚îî‚îÄ‚îÄ state.py          # Defini√ß√£o de estado do agente
‚îÇ
‚îú‚îÄ‚îÄ main.py                   # Entry point FastAPI
‚îÇ                            # - Endpoint POST /chat
‚îÇ                            # - Configura√ß√£o CORS
‚îÇ                            # - Invoca√ß√£o do agente
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt          # Depend√™ncias Python
‚îú‚îÄ‚îÄ example.env               # Template de vari√°veis
‚îú‚îÄ‚îÄ .env                     # Credenciais (n√£o commitar!)
‚îî‚îÄ‚îÄ README.md                # Este arquivo
```

## ü§ñ Como Funciona

### Arquitetura do Agente

O agente usa **LangGraph** para implementar um fluxo conversacional com estados:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Usu√°rio   ‚îÇ
‚îÇ "Busco um   ‚îÇ
‚îÇ quarto em   ‚îÇ
‚îÇ Belo        ‚îÇ
‚îÇ Horizonte"  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          START (Estado Inicial)      ‚îÇ
‚îÇ  - messages: hist√≥rico               ‚îÇ
‚îÇ  - context: dados da base            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚Üì
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ search_node   ‚îÇ‚îÄ‚îÄ‚Üí Decide se busca na base
       ‚îÇ (Condicional) ‚îÇ    ou responde diretamente
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ             ‚îÇ
        ‚Üì             ‚Üì
   ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó    ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
   ‚ïë SEARCH ‚ïë    ‚ïë  RESPOND  ‚ïë
   ‚ïö‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïù    ‚ïö‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
        ‚îÇ            ‚îÇ
        ‚Üì            ‚Üì
  [Busca dados] [Gera resposta]
  [Atualiza     [Com contexto]
   contexto]    [ou busca]
        ‚îÇ            ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚Üì
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇrespond_node ‚îÇ‚îÄ‚îÄ‚Üí Gemini 1.5 Flash
       ‚îÇ (LLM Call)  ‚îÇ    gera resposta natural
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚Üì
         ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
         ‚ïë  END   ‚ïë
         ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
              ‚îÇ
              ‚Üì
    { "response": "Encontrei 3 op√ß√µes..." }
```

### Fluxo de Processamento

1. **Recebe mensagem** do usu√°rio via POST `/chat`
2. **Inicializa estado** com hist√≥rico de mensagens
3. **search_node:** Gemini decide se precisa buscar dados ou responder
4. **Roteamento condicional:**
   - Se "SEARCH" ‚Üí carrega dados da base (simulado)
   - Se "RESPOND" ‚Üí pula para gera√ß√£o de resposta
5. **respond_node:** Gemini gera resposta natural usando contexto
6. **Retorna JSON** com resposta do agente

### Principais Componentes

**`simple_agent/agent.py`:**
```python
# Define o grafo LangGraph
workflow = StateGraph(AgentState)
workflow.add_node("search", search_node)
workflow.add_node("respond", respond_node)

# Fluxo condicional
workflow.add_conditional_edges(
    "search",
    route_after_search,  # Decide pr√≥ximo passo
    {"search": "search", "respond": "respond"}
)
```

**`simple_agent/utils/state.py`:**
```python
class AgentState(TypedDict):
    messages: List[BaseMessage]  # Hist√≥rico conversa
    context: str                 # Dados externos
```

**`simple_agent/utils/prompt.py`:**
- Define personalidade do agente
- Instru√ß√µes de formata√ß√£o
- Template de resposta

## üåê Endpoints

### `POST /chat`

Envia mensagem para o agente e recebe resposta.

**Request:**
```json
{
  "message": "Busco um quarto masculino em Belo Horizonte por at√© 800 reais"
}
```

**Response:**
```json
{
  "response": "Encontrei algumas op√ß√µes para voc√™ em Belo Horizonte:\n\n1. Quarto Estudante - R$ 750/m√™s\n   Localiza√ß√£o: Rua dos Estudantes, 123 - Centro\n   Pr√≥ximo √† UFMG\n   Contato: (31) 98765-4321\n\n2. Kitnet Estudantil - R$ 800/m√™s\n   Mais pr√≥ximo √† universidade...",
  "context_used": "sim",
  "model": "gemini-1.5-flash"
}
```

### `GET /`

Health check e documenta√ß√£o.

**Response:**
```json
{
  "message": "UFRoom AI Agent",
  "status": "online",
  "docs": "/docs"
}
```

### `GET /docs`

Documenta√ß√£o interativa Swagger UI (acesse pelo navegador).

## üîß Desenvolvimento

### Testar API

```bash
# Com curl
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Preciso de um quarto em Belo Horizonte"}'

# Com Python requests
python -c "
import requests
response = requests.post('http://localhost:8000/chat', 
    json={'message': 'Busco apartamento para estudantes'})
print(response.json())
"
```

### Logs e Debug

```bash
# Ver logs detalhados do agente
uv run uvicorn main:app --reload --log-level debug

# Logs aparecem no terminal com:
# - Estado do grafo
# - Decis√µes tomadas
# - Contexto usado
# - Resposta gerada
```

### Modificar Comportamento

**Ajustar prompt do agente:**
Edite `simple_agent/utils/prompt.py`:
```python
SYSTEM_PROMPT = """
Voc√™ √© um assistente especializado em...
[Customize aqui]
"""
```

**Adicionar dados de contexto:**
Edite `simple_agent/utils/context.py`:
```python
def load_context():
    # Conectar com API ou banco
    # Buscar an√∫ncios reais
    return formatted_data
```

**Mudar modelo Gemini:**
Edite `simple_agent/agent.py`:
```python
llm = ChatGoogleGenerativeAI(
    model="gemini-1.5-pro",  # Ou gemini-2.0-flash-exp
    temperature=0.7
)
```

## üêõ Troubleshooting

### Erro: `GOOGLE_API_KEY not found`

**Solu√ß√£o:**
```bash
# Verificar se .env existe e cont√©m a chave
cat .env | grep GOOGLE_API_KEY

# Se n√£o, adicione:
echo "GOOGLE_API_KEY=sua_chave_aqui" >> .env
```

### Erro: `Rate limit exceeded`

**Problema:** Limite gratuito Gemini atingido (15 req/min)

**Solu√ß√£o:**
- Aguarde 1 minuto
- Ou configure rate limiting no c√≥digo
- Ou fa√ßa upgrade para API paga

### Erro: `Module not found: langgraph`

**Solu√ß√£o:**
```bash
# Reativar ambiente virtual
source .venv/bin/activate

# Reinstalar depend√™ncias
uv pip install -r requirements.txt
```

### Agente n√£o busca dados

**Problema:** Sempre responde sem buscar contexto

**Solu√ß√£o:**
- Verificar implementa√ß√£o em `context.py`
- Melhorar prompt em `prompt.py` para instruir busca
- Adicionar exemplos de quando buscar

### Performance lenta

**Problema:** Respostas demoram muito

**Solu√ß√£o:**
- Usar `gemini-1.5-flash` em vez de `gemini-1.5-pro` (mais r√°pido)
- Reduzir tamanho do contexto
- Cache de respostas comuns
- Usar `uvicorn` com m√∫ltiplos workers

### Erro de importa√ß√£o `externally-managed-environment`

**Problema:** Sistema operacional n√£o permite pip global

**Solu√ß√£o:**
```bash
# Sempre use ambiente virtual
uv venv --python 3.12
source .venv/bin/activate
uv pip install -r requirements.txt
```

## üöÄ Melhorias Futuras

- [ ] Conectar com API Fastify real para buscar an√∫ncios
- [ ] Implementar mem√≥ria de conversa√ß√£o (hist√≥rico)
- [ ] Adicionar autentica√ß√£o (JWT)
- [ ] Cache de respostas comuns
- [ ] Suporte a m√∫ltiplos idiomas
- [ ] Integra√ß√£o com WhatsApp/Telegram
- [ ] Analytics de conversa√ß√µes
- [ ] Feedback do usu√°rio (√∫til/n√£o √∫til)

## üìö Recursos

- [FastAPI Docs](https://fastapi.tiangolo.com/)
- [LangGraph Docs](https://langchain-ai.github.io/langgraph/)
- [Google Gemini API](https://ai.google.dev/docs)
- [UV Package Manager](https://github.com/astral-sh/uv)

